# Python Examples, common libraries, method use-cases
## Common python

- Catch known exception: `try: - except:`

```python
try:
  print(x)
except:
  print("An exception occurred")
```

## Dataframe
### Most used methods
- Show columns: `dt.columns`

```python
dt = pd.read_csv('example_data.csv')
dt.columns

Index(['Unnamed: 0', 'file_path', 'total_page_count', 'content',
       'clean_content', 'content_stop_words', 'content_stemmed'],
      dtype='object')
```

- Show DataFrame info: `dt.info()`

```python
dt.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 15751 entries, 0 to 15750
Data columns (total 7 columns):
 #   Column              Non-Null Count  Dtype 
---  ------              --------------  ----- 
 0   Unnamed: 0          15751 non-null  int64 
 1   file_path           15751 non-null  object
 2   total_page_count    15751 non-null  int64 
 3   content             15751 non-null  object
 4   clean_content       15751 non-null  object
 5   content_stop_words  15660 non-null  object
 6   content_stemmed     15660 non-null  object
dtypes: int64(2), object(5)
memory usage: 861.5+ KB
```

- Check nan values `dt.isna().sum()`
  
```python
df.isna().sum()

Unnamed: 0             0
file_path              0
total_page_count       0
content                0
clean_content          0
content_stop_words    91
content_stemmed       91
dtype: int64
```

  Show total number of nan values:

  ```python
  df.isna().sum().sum()
  
  182
  ```
- Check a Series contains a given text: `Series.str.contains('text').any()`

```python
rt['Filename'].str.contains('text').any()

False
```

- Drop some rows by index

```python
dx.drop([0,2])
```

- Reindexing: `reset_index`

```python
dtr.reset_index(drop=True, inplace=True)
```

- Get rows and columns by index

```python
# Rows:
dt.iloc[0] # first row of data frame
dt.iloc[1] # second row of data frame
dt.iloc[-1] # last row of data frame
# Columns:
dt.iloc[:,0] # first column of data frame
dt.iloc[:,1] # second column of data frame
dt.iloc[:,-1] # last column of data frame

dt.iloc[0:5] # first five rows of dataframe
dt.iloc[:, 0:2] # first two columns of data frame with all rows
dt.iloc[[0,3,6,24], [0,5,6]] # 1st, 4th, 7th, 25th row + 1st 6th 7th columns.
dt.iloc[0:5, 5:8] # first 5 rows and 5th, 6th, 7th columns of data frame
```

### Playing with pandas DataFrame in CSV

#### Read csv file to `DataFrame`
`df_csv = pd.read_csv('csv_example')`
If the given CSV file does not generated by DataFrame before, it will generate a column **Unnamed**. To eliminate this column, we can save the DataFrame with an **index** parameter:
`df.to_csv('csv_example', index=False)`

#### Playing with header
- By default, the first row is counted as header
`df_csv = pd.read_csv('csv_example', header = 0)`
- Header can be specified as a few rows:
`df_csv = pd.read_csv('csv_example', header=[1,2,5])`
- or a single row in a specified index:
`df_csv = pd.read_csv('csv_example', header=1)`

#### Changing column names
- `df_csv = pd.read_csv('csv_example', names=['a', 'b', 'c'])`
- Even it can be combined with header options:
`df_csv = pd.read_csv('csv_example', names=['a', 'b', 'c'], header=1)`
- Or, we can simply ignore it while exporting to a file:
`df.to_csv('csv_example', index=False, header = False)`

#### Determine delimiter
The default delimiter for CSV is comma ",". However, it could be changed while either in reading or writing.
- Reading: 
`df_csv = pd.read_csv('csv_example', sep=":")`
- Writing:
`df.to_csv('csv_example', index=False, sep=":")`

#### Sorting
- Set first header names then sort y name:
`df_csv.set_index('column_name')`
- Sorting by a column while reading:
`df_csv = pd.read_csv('csv_example', sep=":", index_col=1)`
- even sort by a multiple column while reading:
`df_csv = pd.read_csv('csv_example', sep=":", index_col=[0,2])`

#### Limit the data that will be loaded
- Load only determined first **n** rows
`df_csv = pd.read_csv('csv_example', sep=":", nrows=3)`

#### Empty lines
By default, empty lines are skipped in CSV file format. If you need to take care of empty lines to county empty pages for example, you can count it by marking **skip_blank_lines=False**:
`df_csv = pd.read_csv('csv_example', skip_blank_lines=False, sep=":")`


## Pickling
The pickle module implements binary protocols for serializing and de-serializing a Python object structure. See here for details: https://docs.python.org/3.8/library/pickle.html

### Pandas pickle
  - Load
  
  ```python
  import pandas as pd
  df = pd.read_pickle('data.pkl')  
  ```

  - Store
  
  ```python
  import pandas as pd
  df = pd.DataFrame(..)
  
  df.to_pickle('data.pkl')
  ```
  
### Pickle
  - Load
  
  ```python
  import pandas as pd
  import pickle
  
  f = open('data.pkl', 'rb')
  df = pickle.load(f)
  f.close()
  ```

  - Store
  
  ```python
  import pandas as pd
  import pickle
  
  df = pd.DataFrame(..)
  
  f = open('data.pkl', 'wb')
  pickle.dump(df, f)
  f.close()
  ```
  
  ### Throubleshooting
  
  #### `unsupported pickle protocol: 5`
  
  This problem happens when the machine that you try to read a pickle file is using a different Python version than where the pickle file was created with. For example, the pickle file is created in Python3.8 but you are trying to load it in Python3.6. If you are facing incompatible version problem:
    
  - Store pickle file again with giving specific version (..,protocol=5)
  - You can use <a href="https://pypi.org/project/pickle5/">pickle5</a>
  - Upgrade Python version in your machine or in Google Collab

  
